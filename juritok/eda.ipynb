{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_NAME = \"jorf_2023.csv\"\n",
    "VOC_FILE_NAME = \"jorf_vocabulary.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454301, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>child_id</th>\n",
       "      <th>type</th>\n",
       "      <th>article</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>fr/lr/loi/2023-1380/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFVERS000048734585</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>LOI n° 2023-1380 du 30 décembre 2023 visant à ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I. — Après l'article L. 2122-19 du code généra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>« Art. L. 2122-19-1. — Pour assurer les foncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JORFTEXT000048734585</td>\n",
       "      <td>JORFARTI000048734586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>II. — L'article L. 2122-19-1 du code général d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text_id              child_id  type article  paragraph  \\\n",
       "0  JORFTEXT000048734585                   NaN     0     NaN          0   \n",
       "1  JORFTEXT000048734585  JORFVERS000048734585     0     NaN          0   \n",
       "2  JORFTEXT000048734585  JORFARTI000048734586     1       1          1   \n",
       "3  JORFTEXT000048734585  JORFARTI000048734586     1       1          2   \n",
       "4  JORFTEXT000048734585  JORFARTI000048734586     1       1          3   \n",
       "\n",
       "                                                text  \n",
       "0                     fr/lr/loi/2023-1380/2023-12-31  \n",
       "1  LOI n° 2023-1380 du 30 décembre 2023 visant à ...  \n",
       "2  I. — Après l'article L. 2122-19 du code généra...  \n",
       "3  « Art. L. 2122-19-1. — Pour assurer les foncti...  \n",
       "4  II. — L'article L. 2122-19-1 du code général d...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "directory_path = os.getcwd()\n",
    "df = pd.read_csv(directory_path + \"/\" + DATA_FILE_NAME, sep='|', names= [\"text_id\", \"child_id\", \"type\", \"article\", \"paragraph\", \"text\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"« Art. L. 2122-19-1. — Pour assurer les fonctions liées au secrétariat de mairie dans les communes de moins de 3 500 habitants, le maire nomme un agent aux fonctions de secrétaire général de mairie, sauf s'il nomme un agent pour occuper les fonctions de directeur général des services. Le secrétaire général de mairie peut exercer ses fonctions à temps partiel ou à temps non complet. »\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3, \"text\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and Persist \"text\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406015,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    I. — Après l'article L. 2122-19 du code généra...\n",
       "3    « Art. L. 2122-19-1. — Pour assurer les foncti...\n",
       "4    II. — L'article L. 2122-19-1 du code général d...\n",
       "5    « Art. L. 2122-19-1. — Pour assurer les foncti...\n",
       "6    « Pour assurer les fonctions liées au secrétar...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = df.loc[:,\"text\"][df[\"type\"] == 1] # Type 0 : law title, Type 1: law description, Type 2: TABLE\n",
    "print(df_text.shape)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory_path + \"/\" + VOC_FILE_NAME, mode=\"w\") as f:\n",
    "    f.write('\\n'.join(df_text.astype(str)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tokenizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/adrian/Desktop/NLP/juritok/juritok/jorf_vocabulary.txt\n",
      "  input_format: \n",
      "  model_prefix: juritok\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: /home/adrian/Desktop/NLP/juritok/juritok/jorf_vocabulary.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5374 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 406042 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 12 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=57541646\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9522% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=92\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999522\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 406042 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=39004466\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 359517 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 406042\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 262804\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 262804 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=149638 obj=11.7899 num_tokens=629619 num_tokens/piece=4.20761\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=129993 obj=8.96897 num_tokens=629975 num_tokens/piece=4.84622\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=97471 obj=8.95575 num_tokens=656688 num_tokens/piece=6.73727\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=97414 obj=8.9456 num_tokens=657158 num_tokens/piece=6.74603\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=73057 obj=8.98076 num_tokens=694233 num_tokens/piece=9.50262\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=73056 obj=8.97098 num_tokens=694221 num_tokens/piece=9.50259\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=54792 obj=9.02107 num_tokens=735651 num_tokens/piece=13.4262\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=54791 obj=9.01247 num_tokens=735572 num_tokens/piece=13.4251\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=41093 obj=9.07698 num_tokens=780213 num_tokens/piece=18.9865\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=41093 obj=9.06465 num_tokens=780099 num_tokens/piece=18.9837\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=30819 obj=9.14605 num_tokens=825377 num_tokens/piece=26.7814\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=30819 obj=9.13102 num_tokens=825269 num_tokens/piece=26.7779\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=23114 obj=9.23567 num_tokens=871824 num_tokens/piece=37.7184\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=23114 obj=9.21666 num_tokens=871813 num_tokens/piece=37.718\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=17335 obj=9.34752 num_tokens=922182 num_tokens/piece=53.1977\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=17335 obj=9.32279 num_tokens=922246 num_tokens/piece=53.2014\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13001 obj=9.49496 num_tokens=973558 num_tokens/piece=74.8833\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13001 obj=9.46291 num_tokens=973640 num_tokens/piece=74.8896\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=9750 obj=9.67186 num_tokens=1030320 num_tokens/piece=105.674\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=9750 obj=9.63055 num_tokens=1030524 num_tokens/piece=105.695\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=7312 obj=9.89512 num_tokens=1093882 num_tokens/piece=149.601\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=7312 obj=9.84252 num_tokens=1094014 num_tokens/piece=149.619\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5484 obj=10.1669 num_tokens=1154827 num_tokens/piece=210.581\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5484 obj=10.1026 num_tokens=1155011 num_tokens/piece=210.615\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4113 obj=10.4843 num_tokens=1222302 num_tokens/piece=297.18\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4113 obj=10.4076 num_tokens=1222564 num_tokens/piece=297.244\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3084 obj=10.8633 num_tokens=1289749 num_tokens/piece=418.207\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3084 obj=10.7787 num_tokens=1289855 num_tokens/piece=418.241\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2313 obj=11.3049 num_tokens=1358989 num_tokens/piece=587.544\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2313 obj=11.2055 num_tokens=1358994 num_tokens/piece=587.546\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1734 obj=11.7935 num_tokens=1452285 num_tokens/piece=837.535\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1734 obj=11.6726 num_tokens=1452346 num_tokens/piece=837.57\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1300 obj=12.3388 num_tokens=1531731 num_tokens/piece=1178.25\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1300 obj=12.2165 num_tokens=1531745 num_tokens/piece=1178.27\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1100 obj=12.6062 num_tokens=1564735 num_tokens/piece=1422.49\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1100 obj=12.5439 num_tokens=1564786 num_tokens/piece=1422.53\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: juritok.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: juritok.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(input=directory_path + \"/\" + VOC_FILE_NAME, model_prefix='juritok', vocab_size=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file= directory_path + '/juritok.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 431, 9, 44, 9, 503, 51, 574, 113, 18, 58, 9, 4, 45, 389, 4, 853, 22, 251, 3, 10, 36, 178, 24, 170, 21, 135, 15, 502, 67, 5, 386, 95, 8, 61, 22, 405, 26, 5, 542, 5, 181, 196, 341, 228, 245, 75, 41, 3, 7, 23, 121, 134, 495, 158, 82, 4, 204, 65, 83, 251, 3, 5, 852, 302, 5, 386, 95, 8, 7, 268, 32, 87, 4, 3, 6, 94, 495, 158, 82, 4, 204, 65, 64, 4, 225, 21, 32, 39, 27, 22, 251, 3, 5, 324, 302, 17, 255, 9, 89, 852, 302, 5, 386, 95, 8, 333, 4, 707, 20, 388, 251, 3, 16, 838, 541, 37, 47, 16, 838, 504, 192, 66, 15, 9, 73]\n"
     ]
    }
   ],
   "source": [
    "some_text = df.loc[3, \"text\"]\n",
    "print(sp.encode(some_text, out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁«', '▁Art', '.', '▁L', '.', '▁21', '2', '2-1', '9', '-', '1', '.', '▁', '—', '▁Pour', '▁', 'assurer', '▁les', '▁fonction', 's', '▁l', 'i', 'ées', '▁au', '▁se', 'c', 'ré', 't', 'ari', 'at', '▁de', '▁mai', 'ri', 'e', '▁dans', '▁les', '▁commun', 'es', '▁de', '▁moins', '▁de', '▁3', '▁5', '00', '▁h', 'ab', 'it', 'ant', 's', ',', '▁le', '▁m', 'aire', '▁nom', 'me', '▁un', '▁', 'ag', 'ent', '▁aux', '▁fonction', 's', '▁de', '▁secrétaire', '▁général', '▁de', '▁mai', 'ri', 'e', ',', '▁sa', 'u', 'f', '▁', 's', \"'\", 'il', '▁nom', 'me', '▁un', '▁', 'ag', 'ent', '▁pour', '▁', 'oc', 'c', 'u', 'p', 'er', '▁les', '▁fonction', 's', '▁de', '▁directeur', '▁général', '▁des', '▁services', '.', '▁Le', '▁secrétaire', '▁général', '▁de', '▁mai', 'ri', 'e', '▁peut', '▁', 'exerce', 'r', '▁ses', '▁fonction', 's', '▁à', '▁temps', '▁partie', 'l', '▁ou', '▁à', '▁temps', '▁non', '▁comp', 'le', 't', '.', '▁»']\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode(some_text, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['▁«', '▁Art', '.', '▁L', '.', '▁21', '2', '2-1', '9', '-', '1', '.', '▁', '—', '▁Pour', '▁', 'assurer', '▁les', '▁fonction', 's', '▁l', 'i', 'ées', '▁au', '▁se', 'c', 'ré', 't', 'ari', 'at', '▁de', '▁mai', 'ri', 'e', '▁dans', '▁les', '▁commun', 'es', '▁de', '▁moins', '▁de', '▁3', '▁5', '00', '▁h', 'ab', 'it', 'ant', 's', ',', '▁le', '▁m', 'aire', '▁nom', 'me', '▁un', '▁', 'ag', 'ent', '▁aux', '▁fonction', 's', '▁de', '▁secrétaire', '▁général', '▁de', '▁mai', 'ri', 'e', ',', '▁sa', 'u', 'f', '▁', 's', \"'\", 'il', '▁nom', 'me', '▁un', '▁', 'ag', 'ent', '▁pour', '▁', 'oc', 'c', 'u', 'p', 'er', '▁les', '▁fonction', 's', '▁de', '▁directeur', '▁général', '▁des', '▁services', '.', '▁Le', '▁secrétaire', '▁général', '▁de', '▁mai', 'ri', 'e', '▁peut', '▁', 'exerce', 'r', '▁ses', '▁fonction', 's', '▁à', '▁temps', '▁partie', 'l', '▁ou', '▁à', '▁temps', '▁non', '▁comp', 'le', 't', '.', '▁»']]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_pieces([some_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"« Art. L. 2122-19-1.▁— Pour assurer les fonctions liées au secrétariat de mairie dans les▁communes de moins de 3 500 habitants, le maire nomme un agent aux fonctions de secrétaire général de mairie,▁sauf▁s'il nomme un agent pour occuper les fonctions de directeur général des services. Le secrétaire général de mairie peut exercer ses fonctions à temps partiel ou à temps non complet. »\"]\n"
     ]
    }
   ],
   "source": [
    "print(sp.decode([['▁«', '▁Art', '.', '▁L', '.', '▁', '21', '22', '-', '1', '9', '-', '1', '.', '▁—', '▁Pour', '▁', 'ass', 'ure', 'r', '▁les', '▁fonction', 's', '▁l', 'i', 'é', 'es', '▁au', '▁se', 'c', 'ré', 't', 'ar', 'i', 'at', '▁de', '▁m', 'a', 'ir', 'ie', '▁dans', '▁les', '▁comm', 'une', 's', '▁de', '▁m', 'o', 'in', 's', '▁de', '▁3', '▁5', '0', '0', '▁h', 'ab', 'it', 'ant', 's', ',', '▁le', '▁m', 'aire', '▁n', 'om', 'me', '▁un', '▁', 'ag', 'ent', '▁aux', '▁fonction', 's', '▁de', '▁se', 'c', 'ré', 't', 'aire', '▁général', '▁de', '▁m', 'a', 'ir', 'ie', ',', '▁s', 'a', 'u', 'f', '▁s', \"'\", 'il', '▁n', 'om', 'me', '▁un', '▁', 'ag', 'ent', '▁pour', '▁', 'oc', 'c', 'u', 'p', 'er', '▁les', '▁fonction', 's', '▁de', '▁directeur', '▁général', '▁des', '▁service', 's', '.', '▁Le', '▁se', 'c', 'ré', 't', 'aire', '▁général', '▁de', '▁m', 'a', 'ir', 'ie', '▁peut', '▁ex', 'er', 'c', 'er', '▁se', 's', '▁fonction', 's', '▁à', '▁', 't', 'emp', 's', '▁par', 'ti', 'el', '▁ou', '▁à', '▁', 't', 'emp', 's', '▁n', 'on', '▁comp', 'le', 't', '.', '▁»']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7279e2106b5f68e06c2618675e1a046a844a4dd45209b3209b3cc28bac3fa42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
